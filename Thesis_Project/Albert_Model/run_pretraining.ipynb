{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "718b3ec4-ebf9-4e5a-8d45-5cc395b2eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import time\n",
    "from albert import modeling\n",
    "from albert import optimization\n",
    "from six.moves import range\n",
    "import tensorflow.compat.v1 as tf\n",
    "# from tensorflow.contrib import cluster_resolver as contrib_cluster_resolver\n",
    "# from tensorflow.contrib import data as contrib_data\n",
    "# from tensorflow.contrib import tpu as contrib_tpu\n",
    "from tensorflow.data.experimental import parallel_interleave\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "569e26b8-d1b7-4d87-b0ce-69eaf044dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(albert_config, init_checkpoint, learning_rate,\n",
    "                     num_train_steps, num_warmup_steps, use_tpu,\n",
    "                     use_one_hot_embeddings, optimizer, poly_power,\n",
    "                     start_warmup_step):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "\n",
    "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "    tf.logging.info(\"*** Features ***\")\n",
    "    for name in sorted(features.keys()):\n",
    "      tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
    "\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    masked_lm_positions = features[\"masked_lm_positions\"]\n",
    "    masked_lm_ids = features[\"masked_lm_ids\"]\n",
    "    masked_lm_weights = features[\"masked_lm_weights\"]\n",
    "    # Note: We keep this feature name `next_sentence_labels` to be compatible\n",
    "    # with the original data created by lanzhzh@. However, in the ALBERT case\n",
    "    # it does represent sentence_order_labels.\n",
    "    sentence_order_labels = features[\"next_sentence_labels\"]\n",
    "\n",
    "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    model = modeling.AlbertModel(\n",
    "        config=albert_config,\n",
    "        is_training=is_training,\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        token_type_ids=segment_ids,\n",
    "        use_one_hot_embeddings=use_one_hot_embeddings)\n",
    "\n",
    "    (masked_lm_loss, masked_lm_example_loss,\n",
    "     masked_lm_log_probs) = get_masked_lm_output(albert_config,\n",
    "                                                 model.get_sequence_output(),\n",
    "                                                 model.get_embedding_table(),\n",
    "                                                 masked_lm_positions,\n",
    "                                                 masked_lm_ids,\n",
    "                                                 masked_lm_weights)\n",
    "\n",
    "    (sentence_order_loss, sentence_order_example_loss,\n",
    "     sentence_order_log_probs) = get_sentence_order_output(\n",
    "         albert_config, model.get_pooled_output(), sentence_order_labels)\n",
    "\n",
    "    total_loss = masked_lm_loss + sentence_order_loss\n",
    "\n",
    "    tvars = tf.trainable_variables()\n",
    "\n",
    "    initialized_variable_names = {}\n",
    "    scaffold_fn = None\n",
    "    if init_checkpoint:\n",
    "      tf.logging.info(\"number of hidden group %d to initialize\",\n",
    "                      albert_config.num_hidden_groups)\n",
    "      num_of_initialize_group = 1\n",
    "      if PARAMS_init_from_group0:\n",
    "        num_of_initialize_group = albert_config.num_hidden_groups\n",
    "        if albert_config.net_structure_type > 0:\n",
    "          num_of_initialize_group = albert_config.num_hidden_layers\n",
    "      (assignment_map, initialized_variable_names\n",
    "      ) = modeling.get_assignment_map_from_checkpoint(\n",
    "              tvars, init_checkpoint, num_of_initialize_group)\n",
    "      if use_tpu:\n",
    "\n",
    "        def tpu_scaffold():\n",
    "          for gid in range(num_of_initialize_group):\n",
    "            tf.logging.info(\"initialize the %dth layer\", gid)\n",
    "            tf.logging.info(assignment_map[gid])\n",
    "            tf.train.init_from_checkpoint(init_checkpoint, assignment_map[gid])\n",
    "          return tf.train.Scaffold()\n",
    "\n",
    "        scaffold_fn = tpu_scaffold\n",
    "      else:\n",
    "        for gid in range(num_of_initialize_group):\n",
    "          tf.logging.info(\"initialize the %dth layer\", gid)\n",
    "          tf.logging.info(assignment_map[gid])\n",
    "          tf.train.init_from_checkpoint(init_checkpoint, assignment_map[gid])\n",
    "\n",
    "    tf.logging.info(\"**** Trainable Variables ****\")\n",
    "    for var in tvars:\n",
    "      init_string = \"\"\n",
    "      if var.name in initialized_variable_names:\n",
    "        init_string = \", *INIT_FROM_CKPT*\"\n",
    "      tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
    "                      init_string)\n",
    "\n",
    "    output_spec = None\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      train_op = optimization.create_optimizer(\n",
    "          total_loss, learning_rate, num_train_steps, num_warmup_steps,\n",
    "          use_tpu, optimizer, poly_power, start_warmup_step)\n",
    "\n",
    "      output_spec = tf.estimator.tpu.TPUEstimatorSpec(\n",
    "          mode=mode,\n",
    "          loss=total_loss,\n",
    "          train_op=train_op,\n",
    "          scaffold_fn=scaffold_fn)\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "\n",
    "      def metric_fn(*args):\n",
    "        \"\"\"Computes the loss and accuracy of the model.\"\"\"\n",
    "        (masked_lm_example_loss, masked_lm_log_probs, masked_lm_ids,\n",
    "         masked_lm_weights, sentence_order_example_loss,\n",
    "         sentence_order_log_probs, sentence_order_labels) = args[:7]\n",
    "\n",
    "\n",
    "        masked_lm_log_probs = tf.reshape(masked_lm_log_probs,\n",
    "                                         [-1, masked_lm_log_probs.shape[-1]])\n",
    "        masked_lm_predictions = tf.argmax(\n",
    "            masked_lm_log_probs, axis=-1, output_type=tf.int32)\n",
    "        masked_lm_example_loss = tf.reshape(masked_lm_example_loss, [-1])\n",
    "        masked_lm_ids = tf.reshape(masked_lm_ids, [-1])\n",
    "        masked_lm_weights = tf.reshape(masked_lm_weights, [-1])\n",
    "        masked_lm_accuracy = tf.metrics.accuracy(\n",
    "            labels=masked_lm_ids,\n",
    "            predictions=masked_lm_predictions,\n",
    "            weights=masked_lm_weights)\n",
    "        masked_lm_mean_loss = tf.metrics.mean(\n",
    "            values=masked_lm_example_loss, weights=masked_lm_weights)\n",
    "\n",
    "        metrics = {\n",
    "            \"masked_lm_accuracy\": masked_lm_accuracy,\n",
    "            \"masked_lm_loss\": masked_lm_mean_loss,\n",
    "        }\n",
    "\n",
    "        sentence_order_log_probs = tf.reshape(\n",
    "            sentence_order_log_probs, [-1, sentence_order_log_probs.shape[-1]])\n",
    "        sentence_order_predictions = tf.argmax(\n",
    "            sentence_order_log_probs, axis=-1, output_type=tf.int32)\n",
    "        sentence_order_labels = tf.reshape(sentence_order_labels, [-1])\n",
    "        sentence_order_accuracy = tf.metrics.accuracy(\n",
    "            labels=sentence_order_labels,\n",
    "            predictions=sentence_order_predictions)\n",
    "        sentence_order_mean_loss = tf.metrics.mean(\n",
    "            values=sentence_order_example_loss)\n",
    "        metrics.update({\n",
    "            \"sentence_order_accuracy\": sentence_order_accuracy,\n",
    "            \"sentence_order_loss\": sentence_order_mean_loss\n",
    "        })\n",
    "        return metrics\n",
    "\n",
    "      metric_values = [\n",
    "          masked_lm_example_loss, masked_lm_log_probs, masked_lm_ids,\n",
    "          masked_lm_weights, sentence_order_example_loss,\n",
    "          sentence_order_log_probs, sentence_order_labels\n",
    "      ]\n",
    "\n",
    "      eval_metrics = (metric_fn, metric_values)\n",
    "\n",
    "      output_spec = tf.estimator.tpu.TPUEstimatorSpec(\n",
    "          mode=mode,\n",
    "          loss=total_loss,\n",
    "          eval_metrics=eval_metrics,\n",
    "          scaffold_fn=scaffold_fn)\n",
    "    else:\n",
    "      raise ValueError(\"Only TRAIN and EVAL modes are supported: %s\" % (mode))\n",
    "\n",
    "    return output_spec\n",
    "\n",
    "  return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e01fd95-9745-4c03-8956-2ce72fcf816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masked_lm_output(albert_config, input_tensor, output_weights, positions,\n",
    "                         label_ids, label_weights):\n",
    "  \"\"\"Get loss and log probs for the masked LM.\"\"\"\n",
    "  input_tensor = gather_indexes(input_tensor, positions)\n",
    "\n",
    "\n",
    "  with tf.variable_scope(\"cls/predictions\"):\n",
    "    # We apply one more non-linear transformation before the output layer.\n",
    "    # This matrix is not used after pre-training.\n",
    "    with tf.variable_scope(\"transform\"):\n",
    "      input_tensor = tf.layers.dense(\n",
    "          input_tensor,\n",
    "          units=albert_config.embedding_size,\n",
    "          activation=modeling.get_activation(albert_config.hidden_act),\n",
    "          kernel_initializer=modeling.create_initializer(\n",
    "              albert_config.initializer_range))\n",
    "      input_tensor = modeling.layer_norm(input_tensor)\n",
    "\n",
    "    # The output weights are the same as the input embeddings, but there is\n",
    "    # an output-only bias for each token.\n",
    "    output_bias = tf.get_variable(\n",
    "        \"output_bias\",\n",
    "        shape=[albert_config.vocab_size],\n",
    "        initializer=tf.zeros_initializer())\n",
    "    logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    label_ids = tf.reshape(label_ids, [-1])\n",
    "    label_weights = tf.reshape(label_weights, [-1])\n",
    "\n",
    "    one_hot_labels = tf.one_hot(\n",
    "        label_ids, depth=albert_config.vocab_size, dtype=tf.float32)\n",
    "\n",
    "    # The `positions` tensor might be zero-padded (if the sequence is too\n",
    "    # short to have the maximum number of predictions). The `label_weights`\n",
    "    # tensor has a value of 1.0 for every real prediction and 0.0 for the\n",
    "    # padding predictions.\n",
    "    per_example_loss = -tf.reduce_sum(log_probs * one_hot_labels, axis=[-1])\n",
    "    numerator = tf.reduce_sum(label_weights * per_example_loss)\n",
    "    denominator = tf.reduce_sum(label_weights) + 1e-5\n",
    "    loss = numerator / denominator\n",
    "\n",
    "  return (loss, per_example_loss, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df23cefe-ce4c-495a-9ee9-d8c70956e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_order_output(albert_config, input_tensor, labels):\n",
    "  \"\"\"Get loss and log probs for the next sentence prediction.\"\"\"\n",
    "\n",
    "  # Simple binary classification. Note that 0 is \"next sentence\" and 1 is\n",
    "  # \"random sentence\". This weight matrix is not used after pre-training.\n",
    "  with tf.variable_scope(\"cls/seq_relationship\"):\n",
    "    output_weights = tf.get_variable(\n",
    "        \"output_weights\",\n",
    "        shape=[2, albert_config.hidden_size],\n",
    "        initializer=modeling.create_initializer(\n",
    "            albert_config.initializer_range))\n",
    "    output_bias = tf.get_variable(\n",
    "        \"output_bias\", shape=[2], initializer=tf.zeros_initializer())\n",
    "\n",
    "    logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "    labels = tf.reshape(labels, [-1])\n",
    "    one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, per_example_loss, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd936140-cd44-4a29-a06c-d65deee98850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_indexes(sequence_tensor, positions):\n",
    "  \"\"\"Gathers the vectors at the specific positions over a minibatch.\"\"\"\n",
    "  sequence_shape = modeling.get_shape_list(sequence_tensor, expected_rank=3)\n",
    "  batch_size = sequence_shape[0]\n",
    "  seq_length = sequence_shape[1]\n",
    "  width = sequence_shape[2]\n",
    "\n",
    "  flat_offsets = tf.reshape(\n",
    "      tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1])\n",
    "  flat_positions = tf.reshape(positions + flat_offsets, [-1])\n",
    "  flat_sequence_tensor = tf.reshape(sequence_tensor,\n",
    "                                    [batch_size * seq_length, width])\n",
    "  output_tensor = tf.gather(flat_sequence_tensor, flat_positions)\n",
    "  return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "137a5042-641c-45cd-8568-d27fafc524a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_builder(input_files,\n",
    "                     max_seq_length,\n",
    "                     max_predictions_per_seq,\n",
    "                     is_training,\n",
    "                     num_cpu_threads=4):\n",
    "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
    "\n",
    "  def input_fn(params):\n",
    "    \"\"\"The actual input function.\"\"\"\n",
    "    batch_size = params[\"batch_size\"]\n",
    "\n",
    "    name_to_features = {\n",
    "        \"input_ids\": tf.FixedLenFeature([max_seq_length], tf.int64),\n",
    "        \"input_mask\": tf.FixedLenFeature([max_seq_length], tf.int64),\n",
    "        \"segment_ids\": tf.FixedLenFeature([max_seq_length], tf.int64),\n",
    "        # Note: We keep this feature name `next_sentence_labels` to be\n",
    "        # compatible with the original data created by lanzhzh@. However, in\n",
    "        # the ALBERT case it does represent sentence_order_labels.\n",
    "        \"next_sentence_labels\": tf.FixedLenFeature([1], tf.int64),\n",
    "    }\n",
    "\n",
    "    if PARAMS_masked_lm_budget:\n",
    "      name_to_features.update({\n",
    "          \"token_boundary\":\n",
    "              tf.FixedLenFeature([max_seq_length], tf.int64)})\n",
    "    else:\n",
    "      name_to_features.update({\n",
    "          \"masked_lm_positions\":\n",
    "              tf.FixedLenFeature([max_predictions_per_seq], tf.int64),\n",
    "          \"masked_lm_ids\":\n",
    "              tf.FixedLenFeature([max_predictions_per_seq], tf.int64),\n",
    "          \"masked_lm_weights\":\n",
    "              tf.FixedLenFeature([max_predictions_per_seq], tf.float32)})\n",
    "\n",
    "    # For training, we want a lot of parallel reading and shuffling.\n",
    "    # For eval, we want no shuffling and parallel reading doesn't matter.\n",
    "    if is_training:\n",
    "      d = tf.data.Dataset.from_tensor_slices(tf.constant(input_files))\n",
    "      d = d.repeat()\n",
    "      d = d.shuffle(buffer_size=len(input_files))\n",
    "\n",
    "      # `cycle_length` is the number of parallel files that get read.\n",
    "      cycle_length = min(num_cpu_threads, len(input_files))\n",
    "\n",
    "      # `sloppy` mode means that the interleaving is not exact. This adds\n",
    "      # even more randomness to the training pipeline.\n",
    "      d = d.apply(parallel_interleave(tf.data.TFRecordDataset, sloppy=is_training, cycle_length=cycle_length))\n",
    "      d = d.shuffle(buffer_size=100)\n",
    "    else:\n",
    "      d = tf.data.TFRecordDataset(input_files)\n",
    "      # Since we evaluate for a fixed number of steps we don't want to encounter\n",
    "      # out-of-range exceptions.\n",
    "      d = d.repeat()\n",
    "\n",
    "    # We must `drop_remainder` on training because the TPU requires fixed\n",
    "    # size dimensions. For eval, we assume we are evaluating on the CPU or GPU\n",
    "    # and we *don't* want to drop the remainder, otherwise we wont cover\n",
    "    # every sample.\n",
    "    d = d.apply(\n",
    "        tf.data.experimental.map_and_batch_with_legacy_function(\n",
    "            lambda record: _decode_record(record, name_to_features),\n",
    "            batch_size=batch_size,\n",
    "            num_parallel_batches=num_cpu_threads,\n",
    "            drop_remainder=True))\n",
    "    tf.logging.info(d)\n",
    "    return d\n",
    "\n",
    "  return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f50c0623-8f36-4485-8235-934b243c6858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _decode_record(record, name_to_features):\n",
    "  \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "  example = tf.parse_single_example(record, name_to_features)\n",
    "\n",
    "  # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
    "  # So cast all int64 to int32.\n",
    "  for name in list(example.keys()):\n",
    "    t = example[name]\n",
    "    if t.dtype == tf.int64:\n",
    "      t = tf.to_int32(t)\n",
    "    example[name] = t\n",
    "\n",
    "  return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe0e1cf-65b2-4854-bf85-c729a3814a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS_input_file = './processed_data/Discharge_summary_pretrain.tfrecord'\n",
    "PARAMS_output_dir = './model/'\n",
    "PARAMS_init_checkpoint = './model/albert_base_v1/model.ckpt-best'\n",
    "PARAMS_albert_config_file = './model/albert_base_v1/albert_config.json'\n",
    "PARAMS_do_train = True\n",
    "PARAMS_do_eval = False\n",
    "PARAMS_train_batch_size=4096\n",
    "PARAMS_eval_batch_size=64\n",
    "PARAMS_max_seq_length=512\n",
    "PARAMS_max_predictions_per_seq=20\n",
    "PARAMS_optimizer='lamb'\n",
    "PARAMS_learning_rate=.00176\n",
    "PARAMS_num_train_steps=10 #125000\n",
    "PARAMS_num_warmup_steps=5 #3125\n",
    "PARAMS_save_checkpoints_steps=5 #5000\n",
    "\n",
    "PARAMS_use_tpu = False\n",
    "PARAMS_master = None\n",
    "PARAMS_keep_checkpoint_max = 5\n",
    "PARAMS_poly_power = 1.0\n",
    "PARAMS_start_warmup_step = 5\n",
    "PARAMS_iterations_per_loop = 1000\n",
    "PARAMS_max_eval_steps = 100\n",
    "PARAMS_init_from_group0 = False\n",
    "PARAMS_num_tpu_cores = 8\n",
    "PARAMS_masked_lm_budget = 0\n",
    "PARAMS_gcp_project = None\n",
    "PARAMS_tpu_zone = None\n",
    "PARAMS_tpu_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ede486e-c377-40b3-bfe6-8019773185fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Input Files ***\n",
      "INFO:tensorflow:  C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\processed_data\\Discharge_summary_pretrain.tfrecord\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x00000257DF30E9D0>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:/Users/XinXining/Desktop/Yale/Thesis_Project/Albert_Model/model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
      "INFO:tensorflow:***** Running training *****\n",
      "WARNING:tensorflow:From C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:400: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From <ipython-input-6-321d5923fc68>:47: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From <ipython-input-6-321d5923fc68>:60: map_and_batch_with_legacy_function (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch()\n",
      "WARNING:tensorflow:From C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:465: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:<_MapAndBatchDataset shapes: {input_ids: (4096, 512), input_mask: (4096, 512), masked_lm_ids: (4096, 20), masked_lm_positions: (4096, 20), masked_lm_weights: (4096, 20), next_sentence_labels: (4096, 1), segment_ids: (4096, 512)}, types: {input_ids: tf.int32, input_mask: tf.int32, masked_lm_ids: tf.int32, masked_lm_positions: tf.int32, masked_lm_weights: tf.float32, next_sentence_labels: tf.int32, segment_ids: tf.int32}>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running train on CPU/GPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (4096, 512)\n",
      "INFO:tensorflow:  name = input_mask, shape = (4096, 512)\n",
      "INFO:tensorflow:  name = masked_lm_ids, shape = (4096, 20)\n",
      "INFO:tensorflow:  name = masked_lm_positions, shape = (4096, 20)\n",
      "INFO:tensorflow:  name = masked_lm_weights, shape = (4096, 20)\n",
      "INFO:tensorflow:  name = next_sentence_labels, shape = (4096, 1)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (4096, 512)\n",
      "INFO:tensorflow:number of hidden group 1 to initialize\n",
      "INFO:tensorflow:name bert/embeddings/word_embeddings match to bert/embeddings/word_embeddings\n",
      "INFO:tensorflow:name bert/embeddings/token_type_embeddings match to bert/embeddings/token_type_embeddings\n",
      "INFO:tensorflow:name bert/embeddings/position_embeddings match to bert/embeddings/position_embeddings\n",
      "INFO:tensorflow:name bert/embeddings/layer_normalization/gamma does not get matched\n",
      "INFO:tensorflow:name bert/embeddings/layer_normalization/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/embedding_hidden_mapping_in/kernel match to bert/encoder/embedding_hidden_mapping_in/kernel\n",
      "INFO:tensorflow:name bert/encoder/embedding_hidden_mapping_in/bias match to bert/encoder/embedding_hidden_mapping_in/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_1/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_1/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_2/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_2/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_3/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_3/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_4/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_4/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_5/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_5/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_6/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_6/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_7/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_7/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_8/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_8/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_9/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_9/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_10/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_10/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_11/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_11/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_12/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_12/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_13/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_13/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_14/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_14/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_15/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_15/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_16/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_16/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_17/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_17/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_18/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_18/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_19/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_19/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_20/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_20/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_21/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_21/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_22/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_22/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_23/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_23/beta does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_24/gamma does not get matched\n",
      "INFO:tensorflow:name bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_24/beta does not get matched\n",
      "INFO:tensorflow:name bert/pooler/dense/kernel match to bert/pooler/dense/kernel\n",
      "INFO:tensorflow:name bert/pooler/dense/bias match to bert/pooler/dense/bias\n",
      "INFO:tensorflow:name cls/predictions/transform/dense/kernel match to cls/predictions/transform/dense/kernel\n",
      "INFO:tensorflow:name cls/predictions/transform/dense/bias match to cls/predictions/transform/dense/bias\n",
      "INFO:tensorflow:name cls/predictions/transform/layer_normalization_25/gamma does not get matched\n",
      "INFO:tensorflow:name cls/predictions/transform/layer_normalization_25/beta does not get matched\n",
      "INFO:tensorflow:name cls/predictions/output_bias match to cls/predictions/output_bias\n",
      "INFO:tensorflow:name cls/seq_relationship/output_weights match to cls/seq_relationship/output_weights\n",
      "INFO:tensorflow:name cls/seq_relationship/output_bias match to cls/seq_relationship/output_bias\n",
      "INFO:tensorflow:initialize the 0th layer\n",
      "INFO:tensorflow:OrderedDict([('bert/embeddings/word_embeddings', 'bert/embeddings/word_embeddings'), ('bert/embeddings/token_type_embeddings', 'bert/embeddings/token_type_embeddings'), ('bert/embeddings/position_embeddings', 'bert/embeddings/position_embeddings'), ('bert/encoder/embedding_hidden_mapping_in/kernel', 'bert/encoder/embedding_hidden_mapping_in/kernel'), ('bert/encoder/embedding_hidden_mapping_in/bias', 'bert/encoder/embedding_hidden_mapping_in/bias'), ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel', 'bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel'), ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias', 'bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias'), ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel', 'bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel'), ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias', 'bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias'), ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel', 'bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel'), ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias', 'bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias'), ('bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel', 'bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel'), ('bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias', 'bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias'), ('bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel', 'bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel'), ('bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias', 'bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias'), ('bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel', 'bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel'), ('bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias', 'bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias'), ('bert/pooler/dense/kernel', 'bert/pooler/dense/kernel'), ('bert/pooler/dense/bias', 'bert/pooler/dense/bias'), ('cls/predictions/transform/dense/kernel', 'cls/predictions/transform/dense/kernel'), ('cls/predictions/transform/dense/bias', 'cls/predictions/transform/dense/bias'), ('cls/predictions/output_bias', 'cls/predictions/output_bias'), ('cls/seq_relationship/output_weights', 'cls/seq_relationship/output_weights'), ('cls/seq_relationship/output_bias', 'cls/seq_relationship/output_bias')])\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30000, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/layer_normalization/gamma:0, shape = (128,)\n",
      "INFO:tensorflow:  name = bert/embeddings/layer_normalization/beta:0, shape = (128,)\n",
      "INFO:tensorflow:  name = bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_1/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_1/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_2/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_2/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_3/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_3/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_4/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_4/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_5/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_5/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_6/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_6/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_7/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_7/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_8/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_8/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_9/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_9/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_10/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_10/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_11/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_11/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_12/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_12/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_13/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_13/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_14/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_14/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_15/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_15/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_16/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_16/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_17/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_17/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_18/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_18/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_19/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_19/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_20/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_20/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_21/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_21/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_22/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_22/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_23/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_23/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_24/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_24/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/predictions/transform/dense/kernel:0, shape = (768, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/predictions/transform/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/predictions/transform/layer_normalization_25/gamma:0, shape = (128,)\n",
      "INFO:tensorflow:  name = cls/predictions/transform/layer_normalization_25/beta:0, shape = (128,)\n",
      "INFO:tensorflow:  name = cls/predictions/output_bias:0, shape = (30000,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/seq_relationship/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/seq_relationship/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:++++++ warmup starts at step 5, for 5 steps ++++++\n",
      "INFO:tensorflow:using lamb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\modeling.py:252: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.pooled_output = tf.layers.dense(\n",
      "C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\keras\\legacy_tf_layers\\core.py:255: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "<ipython-input-3-a9c4ee69f617>:11: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  input_tensor = tf.layers.dense(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:/Users/XinXining/Desktop/Yale/Thesis_Project/Albert_Model/model/model.ckpt.\n",
      "INFO:tensorflow:training_loop marked as finished\n",
      "WARNING:tensorflow:Reraising captured error\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Failed to create a NewWriteableFile: C:/Users/XinXining/Desktop/Yale/Thesis_Project/Albert_Model/model/model.ckpt-0_temp\\part-00000-of-00001.data-00000-of-00001.tempstate99496378179852786 : The system cannot find the path specified.\r\n; No such process\n\t [[node save/SaveV2\n (defined at C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1512)\n]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node save/SaveV2:\nIn[0] save/ShardedFilename:\t\nIn[1] save/SaveV2/tensor_names:\t\nIn[2] save/SaveV2/shape_and_slices:\t\nIn[3] bert/embeddings/layer_normalization/beta/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer_utils.py:117)\t\nIn[4] bert/embeddings/layer_normalization/beta/adam_m/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\lamb_optimizer.py:76)\t\nIn[5] bert/embeddings/layer_normalization/beta/adam_v/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\lamb_optimizer.py:82)\t\nIn[6] bert/embeddings/layer_normalization/gamma/Read/ReadVariableOp:\t\nIn[7] bert/embeddings/layer_normalization/gamma/adam_m/Read/ReadVariableOp:\t\nIn[8] bert/embeddings/layer_normalization/gamma/adam_v/Read/ReadVariableOp:\t\nIn[9] bert/embeddings/position_embeddings/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\modeling.py:602)\t\nIn[10] bert/embeddings/position_embeddings/adam_m/Read/ReadVariableOp:\t\nIn[11] bert/embeddings/position_embeddings/adam_v/Read/ReadVariableOp:\t\nIn[12] bert/embeddings/token_type_embeddings/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\modeling.py:582)\t\nIn[13] bert/embeddings/token_type_embeddings/adam_m/Read/ReadVariableOp:\t\nIn[14] bert/embeddings/token_type_embeddings/adam_v/Read/ReadVariableOp:\t\nIn[15] bert/embeddings/word_embeddings/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\modeling.py:512)\t\nIn[16] bert/embeddings/word_embeddings/adam_m/Read/ReadVariableOp:\t\nIn[17] bert/embeddings/word_embeddings/adam_v/Read/ReadVariableOp:\t\nIn[18] bert/encoder/embedding_hidden_mapping_in/bias/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\modeling.py:781)\t\nIn[19] bert/encoder/embedding_hidden_mapping_in/bias/adam_m/Read/ReadVariableOp:\t\nIn[20] bert/encoder/embedding_hidden_mapping_in/bias/adam_v/Read/ReadVariableOp:\t\nIn[21] bert/encoder/embedding_hidden_mapping_in/kernel/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\modeling.py:777)\t\nIn[22] bert/encoder/embedding_hidden_mapping_in/kernel/adam_m/Read/ReadVariableOp:\t\nIn[23] bert/encoder/embedding_hidden_mapping_in/kernel/adam_v/Read/ReadVariableOp:\t\nIn[24] bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\modeling.py:739)\t\nIn[25] bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias/adam_m/Read/ReadVariableOp:\t\nIn[26] bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias/adam_v/Read/ReadVariableOp:\t\nIn[27] bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\modeling.py:734)\t\nIn[28] bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel/adam_m/Read/ReadVariableOp:\t\nIn[29] bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel/adam_v/Read/ReadVariableOp:\t\nIn[30] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\modeling.py:693)\t\nIn[31] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias/adam_m/Read/ReadVariableOp:\t\nIn[32] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias/adam_v/Read/ReadVariableOp:\t\nIn[33] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\modeling.py:688)\t\nIn[34] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel/adam_m/Read/ReadVariableOp:\t\nIn[35] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel/adam_v/Read/ReadVariableOp:\t\nIn[36] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias/Read/ReadVariableOp:\t\nIn[37] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias/adam_m/Read/ReadVariableOp:\t\nIn[38] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias/adam_v/Read/ReadVariableOp:\t\nIn[39] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel/Read/ReadVariableOp:\t\nIn[40] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel/adam_m/Read/ReadVariableOp:\t\nIn[41] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel/adam_v/Read/ReadVariableOp:\t\nIn[42] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias/Read/ReadVariableOp:\t\nIn[43] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias/adam_m/Read/ReadVariableOp:\t\nIn[44] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias/adam_v/Read/ReadVariableOp:\t\nIn[45] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel/Read/ReadVariableOp:\t\nIn[46] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel/adam_m/Read/ReadVariableOp:\t\nIn[47] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel/adam_v/Read/ReadVariableOp:\t\nIn[48] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias/Read/ReadVariableOp:\t\nIn[49] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias/adam_m/Read/ReadVariableOp:\t\nIn[50] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias/adam_v/Read/ReadVariableOp:\t\nIn[51] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel/Read/ReadVariableOp:\t\nIn[52] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel/adam_m/Read/ReadVariableOp:\t\nIn[53] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel/adam_v/Read/ReadVariableOp:\t\nIn[54] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias/Read/ReadVariableOp:\t\nIn[55] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias/adam_m/Read/ReadVariableOp:\t\nIn[56] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias/adam_v/Read/ReadVariableOp:\t\nIn[57] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel/Read/ReadVariableOp:\t\nIn[58] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel/adam_m/Read/ReadVariableOp:\t\nIn[59] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel/adam_v/Read/ReadVariableOp:\t\nIn[60] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_1/beta/Read/ReadVariableOp:\t\nIn[61] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_1/beta/adam_m/Read/ReadVariableOp:\t\nIn[62] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_1/beta/adam_v/Read/ReadVariableOp:\t\nIn[63] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_1/gamma/Read/ReadVariableOp:\t\nIn[64] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_1/gamma/adam_m/Read/ReadVariableOp:\t\nIn[65] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_1/gamma/adam_v/Read/ReadVariableOp:\t\nIn[66] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_2/beta/Read/ReadVariableOp:\t\nIn[67] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_2/beta/adam_m/Read/ReadVariableOp:\t\nIn[68] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_2/beta/adam_v/Read/ReadVariableOp:\t\nIn[69] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_2/gamma/Read/ReadVariableOp:\t\nIn[70] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_2/gamma/adam_m/Read/ReadVariableOp:\t\nIn[71] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_2/gamma/adam_v/Read/ReadVariableOp:\t\nIn[72] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_3/beta/Read/ReadVariableOp:\t\nIn[73] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_3/beta/adam_m/Read/ReadVariableOp:\t\nIn[74] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_3/beta/adam_v/Read/ReadVariableOp:\t\nIn[75] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_3/gamma/Read/ReadVariableOp:\t\nIn[76] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_3/gamma/adam_m/Read/ReadVariableOp:\t\nIn[77] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_3/gamma/adam_v/Read/ReadVariableOp:\t\nIn[78] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_4/beta/Read/ReadVariableOp:\t\nIn[79] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_4/beta/adam_m/Read/ReadVariableOp:\t\nIn[80] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_4/beta/adam_v/Read/ReadVariableOp:\t\nIn[81] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_4/gamma/Read/ReadVariableOp:\t\nIn[82] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_4/gamma/adam_m/Read/ReadVariableOp:\t\nIn[83] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_4/gamma/adam_v/Read/ReadVariableOp:\t\nIn[84] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_21/beta/Read/ReadVariableOp:\t\nIn[85] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_21/beta/adam_m/Read/ReadVariableOp:\t\nIn[86] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_21/beta/adam_v/Read/ReadVariableOp:\t\nIn[87] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_21/gamma/Read/ReadVariableOp:\t\nIn[88] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_21/gamma/adam_m/Read/ReadVariableOp:\t\nIn[89] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_21/gamma/adam_v/Read/ReadVariableOp:\t\nIn[90] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_22/beta/Read/ReadVariableOp:\t\nIn[91] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_22/beta/adam_m/Read/ReadVariableOp:\t\nIn[92] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_22/beta/adam_v/Read/ReadVariableOp:\t\nIn[93] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_22/gamma/Read/ReadVariableOp:\t\nIn[94] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_22/gamma/adam_m/Read/ReadVariableOp:\t\nIn[95] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_22/gamma/adam_v/Read/ReadVariableOp:\t\nIn[96] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_23/beta/Read/ReadVariableOp:\t\nIn[97] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_23/beta/adam_m/Read/ReadVariableOp:\t\nIn[98] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_23/beta/adam_v/Read/ReadVariableOp:\t\nIn[99] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_23/gamma/Read/ReadVariableOp:\t\nIn[100] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_23/gamma/adam_m/Read/ReadVariableOp:\t\nIn[101] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_23/gamma/adam_v/Read/ReadVariableOp:\t\nIn[102] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_24/beta/Read/ReadVariableOp:\t\nIn[103] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_24/beta/adam_m/Read/ReadVariableOp:\t\nIn[104] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_24/beta/adam_v/Read/ReadVariableOp:\t\nIn[105] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_24/gamma/Read/ReadVariableOp:\t\nIn[106] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_24/gamma/adam_m/Read/ReadVariableOp:\t\nIn[107] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_24/gamma/adam_v/Read/ReadVariableOp:\t\nIn[108] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_5/beta/Read/ReadVariableOp:\t\nIn[109] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_5/beta/adam_m/Read/ReadVariableOp:\t\nIn[110] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_5/beta/adam_v/Read/ReadVariableOp:\t\nIn[111] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_5/gamma/Read/ReadVariableOp:\t\nIn[112] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_5/gamma/adam_m/Read/ReadVariableOp:\t\nIn[113] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_5/gamma/adam_v/Read/ReadVariableOp:\t\nIn[114] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_6/beta/Read/ReadVariableOp:\t\nIn[115] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_6/beta/adam_m/Read/ReadVariableOp:\t\nIn[116] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_6/beta/adam_v/Read/ReadVariableOp:\t\nIn[117] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_6/gamma/Read/ReadVariableOp:\t\nIn[118] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_6/gamma/adam_m/Read/ReadVariableOp:\t\nIn[119] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_6/gamma/adam_v/Read/ReadVariableOp:\t\nIn[120] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_7/beta/Read/ReadVariableOp:\t\nIn[121] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_7/beta/adam_m/Read/ReadVariableOp:\t\nIn[122] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_7/beta/adam_v/Read/ReadVariableOp:\t\nIn[123] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_7/gamma/Read/ReadVariableOp:\t\nIn[124] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_7/gamma/adam_m/Read/ReadVariableOp:\t\nIn[125] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_7/gamma/adam_v/Read/ReadVariableOp:\t\nIn[126] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_8/beta/Read/ReadVariableOp:\t\nIn[127] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_8/beta/adam_m/Read/ReadVariableOp:\t\nIn[128] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_8/beta/adam_v/Read/ReadVariableOp:\t\nIn[129] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_8/gamma/Read/ReadVariableOp:\t\nIn[130] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_8/gamma/adam_m/Read/ReadVariableOp:\t\nIn[131] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_8/gamma/adam_v/Read/ReadVariableOp:\t\nIn[132] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_10/beta/Read/ReadVariableOp:\t\nIn[133] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_10/beta/adam_m/Read/ReadVariableOp:\t\nIn[134] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_10/beta/adam_v/Read/ReadVariableOp:\t\nIn[135] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_10/gamma/Read/ReadVariableOp:\t\nIn[136] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_10/gamma/adam_m/Read/ReadVariableOp:\t\nIn[137] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_10/gamma/adam_v/Read/ReadVariableOp:\t\nIn[138] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_9/beta/Read/ReadVariableOp:\t\nIn[139] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_9/beta/adam_m/Read/ReadVariableOp:\t\nIn[140] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_9/beta/adam_v/Read/ReadVariableOp:\t\nIn[141] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_9/gamma/Read/ReadVariableOp:\t\nIn[142] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_9/gamma/adam_m/Read/ReadVariableOp:\t\nIn[143] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_9/gamma/adam_v/Read/ReadVariableOp:\t\nIn[144] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_11/beta/Read/ReadVariableOp:\t\nIn[145] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_11/beta/adam_m/Read/ReadVariableOp:\t\nIn[146] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_11/beta/adam_v/Read/ReadVariableOp:\t\nIn[147] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_11/gamma/Read/ReadVariableOp:\t\nIn[148] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_11/gamma/adam_m/Read/ReadVariableOp:\t\nIn[149] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_11/gamma/adam_v/Read/ReadVariableOp:\t\nIn[150] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_12/beta/Read/ReadVariableOp:\t\nIn[151] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_12/beta/adam_m/Read/ReadVariableOp:\t\nIn[152] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_12/beta/adam_v/Read/ReadVariableOp:\t\nIn[153] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_12/gamma/Read/ReadVariableOp:\t\nIn[154] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_12/gamma/adam_m/Read/ReadVariableOp:\t\nIn[155] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_12/gamma/adam_v/Read/ReadVariableOp:\t\nIn[156] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_13/beta/Read/ReadVariableOp:\t\nIn[157] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_13/beta/adam_m/Read/ReadVariableOp:\t\nIn[158] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_13/beta/adam_v/Read/ReadVariableOp:\t\nIn[159] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_13/gamma/Read/ReadVariableOp:\t\nIn[160] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_13/gamma/adam_m/Read/ReadVariableOp:\t\nIn[161] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_13/gamma/adam_v/Read/ReadVariableOp:\t\nIn[162] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_14/beta/Read/ReadVariableOp:\t\nIn[163] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_14/beta/adam_m/Read/ReadVariableOp:\t\nIn[164] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_14/beta/adam_v/Read/ReadVariableOp:\t\nIn[165] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_14/gamma/Read/ReadVariableOp:\t\nIn[166] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_14/gamma/adam_m/Read/ReadVariableOp:\t\nIn[167] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_14/gamma/adam_v/Read/ReadVariableOp:\t\nIn[168] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_15/beta/Read/ReadVariableOp:\t\nIn[169] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_15/beta/adam_m/Read/ReadVariableOp:\t\nIn[170] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_15/beta/adam_v/Read/ReadVariableOp:\t\nIn[171] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_15/gamma/Read/ReadVariableOp:\t\nIn[172] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_15/gamma/adam_m/Read/ReadVariableOp:\t\nIn[173] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_15/gamma/adam_v/Read/ReadVariableOp:\t\nIn[174] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_16/beta/Read/ReadVariableOp:\t\nIn[175] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_16/beta/adam_m/Read/ReadVariableOp:\t\nIn[176] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_16/beta/adam_v/Read/ReadVariableOp:\t\nIn[177] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_16/gamma/Read/ReadVariableOp:\t\nIn[178] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_16/gamma/adam_m/Read/ReadVariableOp:\t\nIn[179] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_16/gamma/adam_v/Read/ReadVariableOp:\t\nIn[180] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_17/beta/Read/ReadVariableOp:\t\nIn[181] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_17/beta/adam_m/Read/ReadVariableOp:\t\nIn[182] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_17/beta/adam_v/Read/ReadVariableOp:\t\nIn[183] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_17/gamma/Read/ReadVariableOp:\t\nIn[184] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_17/gamma/adam_m/Read/ReadVariableOp:\t\nIn[185] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_17/gamma/adam_v/Read/ReadVariableOp:\t\nIn[186] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_18/beta/Read/ReadVariableOp:\t\nIn[187] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_18/beta/adam_m/Read/ReadVariableOp:\t\nIn[188] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_18/beta/adam_v/Read/ReadVariableOp:\t\nIn[189] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_18/gamma/Read/ReadVariableOp:\t\nIn[190] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_18/gamma/adam_m/Read/ReadVariableOp:\t\nIn[191] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_18/gamma/adam_v/Read/ReadVariableOp:\t\nIn[192] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_19/beta/Read/ReadVariableOp:\t\nIn[193] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_19/beta/adam_m/Read/ReadVariableOp:\t\nIn[194] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_19/beta/adam_v/Read/ReadVariableOp:\t\nIn[195] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_19/gamma/Read/ReadVariableOp:\t\nIn[196] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_19/gamma/adam_m/Read/ReadVariableOp:\t\nIn[197] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_19/gamma/adam_v/Read/ReadVariableOp:\t\nIn[198] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_20/beta/Read/ReadVariableOp:\t\nIn[199] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_20/beta/adam_m/Read/ReadVariableOp:\t\nIn[200] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_20/beta/adam_v/Read/ReadVariableOp:\t\nIn[201] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_20/gamma/Read/ReadVariableOp:\t\nIn[202] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_20/gamma/adam_m/Read/ReadVariableOp:\t\nIn[203] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_20/gamma/adam_v/Read/ReadVariableOp:\t\nIn[204] bert/pooler/dense/bias/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer_v1.py:423)\t\nIn[205] bert/pooler/dense/bias/adam_m/Read/ReadVariableOp:\t\nIn[206] bert/pooler/dense/bias/adam_v/Read/ReadVariableOp:\t\nIn[207] bert/pooler/dense/kernel/Read/ReadVariableOp:\t\nIn[208] bert/pooler/dense/kernel/adam_m/Read/ReadVariableOp:\t\nIn[209] bert/pooler/dense/kernel/adam_v/Read/ReadVariableOp:\t\nIn[210] cls/predictions/output_bias/Read/ReadVariableOp (defined at <ipython-input-3-a9c4ee69f617>:21)\t\nIn[211] cls/predictions/output_bias/adam_m/Read/ReadVariableOp:\t\nIn[212] cls/predictions/output_bias/adam_v/Read/ReadVariableOp:\t\nIn[213] cls/predictions/transform/dense/bias/Read/ReadVariableOp:\t\nIn[214] cls/predictions/transform/dense/bias/adam_m/Read/ReadVariableOp:\t\nIn[215] cls/predictions/transform/dense/bias/adam_v/Read/ReadVariableOp:\t\nIn[216] cls/predictions/transform/dense/kernel/Read/ReadVariableOp:\t\nIn[217] cls/predictions/transform/dense/kernel/adam_m/Read/ReadVariableOp:\t\nIn[218] cls/predictions/transform/dense/kernel/adam_v/Read/ReadVariableOp:\t\nIn[219] cls/predictions/transform/layer_normalization_25/beta/Read/ReadVariableOp:\t\nIn[220] cls/predictions/transform/layer_normalization_25/beta/adam_m/Read/ReadVariableOp:\t\nIn[221] cls/predictions/transform/layer_normalization_25/beta/adam_v/Read/ReadVariableOp:\t\nIn[222] cls/predictions/transform/layer_normalization_25/gamma/Read/ReadVariableOp:\t\nIn[223] cls/predictions/transform/layer_normalization_25/gamma/adam_m/Read/ReadVariableOp:\t\nIn[224] cls/predictions/transform/layer_normalization_25/gamma/adam_v/Read/ReadVariableOp:\t\nIn[225] cls/seq_relationship/output_bias/Read/ReadVariableOp (defined at <ipython-input-4-fb70aba96a2b>:12)\t\nIn[226] cls/seq_relationship/output_bias/adam_m/Read/ReadVariableOp:\t\nIn[227] cls/seq_relationship/output_bias/adam_v/Read/ReadVariableOp:\t\nIn[228] cls/seq_relationship/output_weights/Read/ReadVariableOp (defined at <ipython-input-4-fb70aba96a2b>:7)\t\nIn[229] cls/seq_relationship/output_weights/adam_m/Read/ReadVariableOp:\t\nIn[230] cls/seq_relationship/output_weights/adam_v/Read/ReadVariableOp:\t\nIn[231] global_step/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py:147)\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 381, in dispatch_queue\n>>>     yield self.process_one()\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 250, in wrapper\n>>>     runner = Runner(ctx_run, result, future, yielded)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 741, in __init__\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-9-d55d79ca8a29>\", line 65, in <module>\n>>>     estimator.train(input_fn=train_input_fn, max_steps=PARAMS_num_train_steps)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 3092, in train\n>>>     return super(TPUEstimator, self).train(\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 360, in train\n>>>     loss = self._train_model(input_fn, hooks, saving_listeners)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1186, in _train_model\n>>>     return self._train_model_default(input_fn, hooks, saving_listeners)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1217, in _train_model_default\n>>>     return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1512, in _train_with_estimator_spec\n>>>     with training.MonitoredTrainingSession(\n>>> \n\nOriginal stack trace for 'save/SaveV2':\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 381, in dispatch_queue\n    yield self.process_one()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 250, in wrapper\n    runner = Runner(ctx_run, result, future, yielded)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 741, in __init__\n    self.ctx_run(self.run)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n    self.do_execute(\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n    result = self._run_cell(\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-d55d79ca8a29>\", line 65, in <module>\n    estimator.train(input_fn=train_input_fn, max_steps=PARAMS_num_train_steps)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 3092, in train\n    return super(TPUEstimator, self).train(\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 360, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1186, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1217, in _train_model_default\n    return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1512, in _train_with_estimator_spec\n    with training.MonitoredTrainingSession(\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 613, in MonitoredTrainingSession\n    return MonitoredSession(\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1058, in __init__\n    super(MonitoredSession, self).__init__(\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 761, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1267, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1272, in _create_session\n    return self._sess_creator.create_session()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 914, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 672, in create_session\n    self._scaffold.finalize()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 244, in finalize\n    self._saver.build()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 935, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 963, in _build\n    self.saver_def = self._builder._build_internal(  # pylint: disable=protected-access\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 525, in _build_internal\n    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 317, in _AddShardedSaveOps\n    return self._AddShardedSaveOpsForV2(filename_tensor, per_device)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 291, in _AddShardedSaveOpsForV2\n    sharded_saves.append(self._AddSaveOps(sharded_filename, saveables))\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 223, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 138, in save_op\n    return io_ops.save_v2(filename_tensor, tensor_names, tensor_slices,\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1712, in save_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 744, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3697, in _create_op_internal\n    ret = Operation(\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2101, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1379\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1380\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1381\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1362\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[0;32m   1364\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1455\u001b[0m                           run_metadata):\n\u001b[1;32m-> 1456\u001b[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[0;32m   1457\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Failed to create a NewWriteableFile: C:/Users/XinXining/Desktop/Yale/Thesis_Project/Albert_Model/model/model.ckpt-0_temp\\part-00000-of-00001.data-00000-of-00001.tempstate99496378179852786 : The system cannot find the path specified.\r\n; No such process\n\t [[{{node save/SaveV2}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d55d79ca8a29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mmax_predictions_per_seq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPARAMS_max_predictions_per_seq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         is_training=True)\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPARAMS_num_train_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mPARAMS_do_eval\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m   3100\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3101\u001b[0m       \u001b[0mrendezvous\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training_loop'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3102\u001b[1;33m       \u001b[0mrendezvous\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3104\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\error_handling.py\u001b[0m in \u001b[0;36mraise_errors\u001b[1;34m(self, timeout_sec)\u001b[0m\n\u001b[0;32m    148\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Reraising captured error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkept_errors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m   3090\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rendezvous\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_fn_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrendezvous\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3091\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3092\u001b[1;33m       return super(TPUEstimator, self).train(\n\u001b[0m\u001b[0;32m   3093\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3094\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1184\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1215\u001b[0m                                            self.config)\n\u001b[0;32m   1216\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0m\u001b[0;32m   1218\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m                                              saving_listeners)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[1;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[0;32m   1510\u001b[0m                   output_dir=self._config.model_dir))\n\u001b[0;32m   1511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1512\u001b[1;33m     with training.MonitoredTrainingSession(\n\u001b[0m\u001b[0;32m   1513\u001b[0m         \u001b[0mmaster\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaster\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1514\u001b[0m         \u001b[0mis_chief\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_chief\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mMonitoredTrainingSession\u001b[1;34m(master, is_chief, checkpoint_dir, scaffold, hooks, chief_only_hooks, save_checkpoint_secs, save_summaries_steps, save_summaries_secs, config, stop_grace_period_secs, log_step_count_steps, max_wait_secs, save_checkpoint_steps, summary_dir, save_graph_def)\u001b[0m\n\u001b[0;32m    611\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[0mall_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 613\u001b[1;33m   return MonitoredSession(\n\u001b[0m\u001b[0;32m    614\u001b[0m       \u001b[0msession_creator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession_creator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[0;32m   1056\u001b[0m                \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m                stop_grace_period_secs=120):\n\u001b[1;32m-> 1058\u001b[1;33m     super(MonitoredSession, self).__init__(\n\u001b[0m\u001b[0;32m   1059\u001b[0m         \u001b[0msession_creator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[0;32m    759\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0;32m    760\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sess_creator)\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \"\"\"\n\u001b[0;32m   1266\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m     \u001b[0m_WrappedSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1272\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1273\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m         logging.info(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Inform the hooks that a new session has been created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m         \u001b[0mhook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_sess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m       return _CoordinatedSession(\n\u001b[0;32m    923\u001b[0m           \u001b[0m_HookedSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_sess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoord\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\u001b[0m in \u001b[0;36mafter_create_session\u001b[1;34m(self, session, coord)\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_summary_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_meta_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m     \u001b[1;31m# The checkpoint saved here is the state at step \"global_step\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    604\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_last_triggered_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(self, session, step)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Saving checkpoints for %d into %s.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m     self._get_saver().save(session, self._save_path, global_step=step,\n\u001b[0m\u001b[0;32m    636\u001b[0m                            write_meta_graph=self._save_graph_def)\n\u001b[0;32m    637\u001b[0m     self._summary_writer.add_session_log(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs, save_debug_info)\u001b[0m\n\u001b[0;32m   1293\u001b[0m               \"Parent directory of {} doesn't exist, can't save.\".format(\n\u001b[0;32m   1294\u001b[0m                   save_path))\n\u001b[1;32m-> 1295\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs, save_debug_info)\u001b[0m\n\u001b[0;32m   1274\u001b[0m           \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1275\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1276\u001b[1;33m           model_checkpoint_path = sess.run(\n\u001b[0m\u001b[0;32m   1277\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m               {self.saver_def.filename_tensor_name: checkpoint_file})\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 970\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    971\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    972\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1191\u001b[0m     \u001b[1;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1194\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1195\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1373\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1374\u001b[0m                            run_metadata)\n\u001b[0;32m   1375\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1397\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1398\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1399\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Failed to create a NewWriteableFile: C:/Users/XinXining/Desktop/Yale/Thesis_Project/Albert_Model/model/model.ckpt-0_temp\\part-00000-of-00001.data-00000-of-00001.tempstate99496378179852786 : The system cannot find the path specified.\r\n; No such process\n\t [[node save/SaveV2\n (defined at C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1512)\n]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node save/SaveV2:\nIn[0] save/ShardedFilename:\t\nIn[1] save/SaveV2/tensor_names:\t\nIn[2] save/SaveV2/shape_and_slices:\t\nIn[3] bert/embeddings/layer_normalization/beta/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer_utils.py:117)\t\nIn[4] bert/embeddings/layer_normalization/beta/adam_m/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\lamb_optimizer.py:76)\t\nIn[5] bert/embeddings/layer_normalization/beta/adam_v/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\lamb_optimizer.py:82)\t\nIn[6] bert/embeddings/layer_normalization/gamma/Read/ReadVariableOp:\t\nIn[7] bert/embeddings/layer_normalization/gamma/adam_m/Read/ReadVariableOp:\t\nIn[8] bert/embeddings/layer_normalization/gamma/adam_v/Read/ReadVariableOp:\t\nIn[9] bert/embeddings/position_embeddings/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\modeling.py:602)\t\nIn[10] bert/embeddings/position_embeddings/adam_m/Read/ReadVariableOp:\t\nIn[11] bert/embeddings/position_embeddings/adam_v/Read/ReadVariableOp:\t\nIn[12] bert/embeddings/token_type_embeddings/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\modeling.py:582)\t\nIn[13] bert/embeddings/token_type_embeddings/adam_m/Read/ReadVariableOp:\t\nIn[14] bert/embeddings/token_type_embeddings/adam_v/Read/ReadVariableOp:\t\nIn[15] bert/embeddings/word_embeddings/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\modeling.py:512)\t\nIn[16] bert/embeddings/word_embeddings/adam_m/Read/ReadVariableOp:\t\nIn[17] bert/embeddings/word_embeddings/adam_v/Read/ReadVariableOp:\t\nIn[18] bert/encoder/embedding_hidden_mapping_in/bias/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\modeling.py:781)\t\nIn[19] bert/encoder/embedding_hidden_mapping_in/bias/adam_m/Read/ReadVariableOp:\t\nIn[20] bert/encoder/embedding_hidden_mapping_in/bias/adam_v/Read/ReadVariableOp:\t\nIn[21] bert/encoder/embedding_hidden_mapping_in/kernel/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\modeling.py:777)\t\nIn[22] bert/encoder/embedding_hidden_mapping_in/kernel/adam_m/Read/ReadVariableOp:\t\nIn[23] bert/encoder/embedding_hidden_mapping_in/kernel/adam_v/Read/ReadVariableOp:\t\nIn[24] bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\modeling.py:739)\t\nIn[25] bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias/adam_m/Read/ReadVariableOp:\t\nIn[26] bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias/adam_v/Read/ReadVariableOp:\t\nIn[27] bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\modeling.py:734)\t\nIn[28] bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel/adam_m/Read/ReadVariableOp:\t\nIn[29] bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel/adam_v/Read/ReadVariableOp:\t\nIn[30] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\modeling.py:693)\t\nIn[31] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias/adam_m/Read/ReadVariableOp:\t\nIn[32] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias/adam_v/Read/ReadVariableOp:\t\nIn[33] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\Desktop\\Yale\\Thesis_Project\\Albert_Model\\albert\\modeling.py:688)\t\nIn[34] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel/adam_m/Read/ReadVariableOp:\t\nIn[35] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel/adam_v/Read/ReadVariableOp:\t\nIn[36] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias/Read/ReadVariableOp:\t\nIn[37] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias/adam_m/Read/ReadVariableOp:\t\nIn[38] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias/adam_v/Read/ReadVariableOp:\t\nIn[39] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel/Read/ReadVariableOp:\t\nIn[40] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel/adam_m/Read/ReadVariableOp:\t\nIn[41] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel/adam_v/Read/ReadVariableOp:\t\nIn[42] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias/Read/ReadVariableOp:\t\nIn[43] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias/adam_m/Read/ReadVariableOp:\t\nIn[44] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias/adam_v/Read/ReadVariableOp:\t\nIn[45] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel/Read/ReadVariableOp:\t\nIn[46] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel/adam_m/Read/ReadVariableOp:\t\nIn[47] bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel/adam_v/Read/ReadVariableOp:\t\nIn[48] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias/Read/ReadVariableOp:\t\nIn[49] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias/adam_m/Read/ReadVariableOp:\t\nIn[50] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias/adam_v/Read/ReadVariableOp:\t\nIn[51] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel/Read/ReadVariableOp:\t\nIn[52] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel/adam_m/Read/ReadVariableOp:\t\nIn[53] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel/adam_v/Read/ReadVariableOp:\t\nIn[54] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias/Read/ReadVariableOp:\t\nIn[55] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias/adam_m/Read/ReadVariableOp:\t\nIn[56] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias/adam_v/Read/ReadVariableOp:\t\nIn[57] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel/Read/ReadVariableOp:\t\nIn[58] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel/adam_m/Read/ReadVariableOp:\t\nIn[59] bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel/adam_v/Read/ReadVariableOp:\t\nIn[60] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_1/beta/Read/ReadVariableOp:\t\nIn[61] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_1/beta/adam_m/Read/ReadVariableOp:\t\nIn[62] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_1/beta/adam_v/Read/ReadVariableOp:\t\nIn[63] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_1/gamma/Read/ReadVariableOp:\t\nIn[64] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_1/gamma/adam_m/Read/ReadVariableOp:\t\nIn[65] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_1/gamma/adam_v/Read/ReadVariableOp:\t\nIn[66] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_2/beta/Read/ReadVariableOp:\t\nIn[67] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_2/beta/adam_m/Read/ReadVariableOp:\t\nIn[68] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_2/beta/adam_v/Read/ReadVariableOp:\t\nIn[69] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_2/gamma/Read/ReadVariableOp:\t\nIn[70] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_2/gamma/adam_m/Read/ReadVariableOp:\t\nIn[71] bert/encoder/transformer/group_0/layer_0/inner_group_0/layer_normalization_2/gamma/adam_v/Read/ReadVariableOp:\t\nIn[72] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_3/beta/Read/ReadVariableOp:\t\nIn[73] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_3/beta/adam_m/Read/ReadVariableOp:\t\nIn[74] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_3/beta/adam_v/Read/ReadVariableOp:\t\nIn[75] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_3/gamma/Read/ReadVariableOp:\t\nIn[76] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_3/gamma/adam_m/Read/ReadVariableOp:\t\nIn[77] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_3/gamma/adam_v/Read/ReadVariableOp:\t\nIn[78] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_4/beta/Read/ReadVariableOp:\t\nIn[79] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_4/beta/adam_m/Read/ReadVariableOp:\t\nIn[80] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_4/beta/adam_v/Read/ReadVariableOp:\t\nIn[81] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_4/gamma/Read/ReadVariableOp:\t\nIn[82] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_4/gamma/adam_m/Read/ReadVariableOp:\t\nIn[83] bert/encoder/transformer/group_0_1/layer_1/inner_group_0/layer_normalization_4/gamma/adam_v/Read/ReadVariableOp:\t\nIn[84] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_21/beta/Read/ReadVariableOp:\t\nIn[85] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_21/beta/adam_m/Read/ReadVariableOp:\t\nIn[86] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_21/beta/adam_v/Read/ReadVariableOp:\t\nIn[87] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_21/gamma/Read/ReadVariableOp:\t\nIn[88] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_21/gamma/adam_m/Read/ReadVariableOp:\t\nIn[89] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_21/gamma/adam_v/Read/ReadVariableOp:\t\nIn[90] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_22/beta/Read/ReadVariableOp:\t\nIn[91] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_22/beta/adam_m/Read/ReadVariableOp:\t\nIn[92] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_22/beta/adam_v/Read/ReadVariableOp:\t\nIn[93] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_22/gamma/Read/ReadVariableOp:\t\nIn[94] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_22/gamma/adam_m/Read/ReadVariableOp:\t\nIn[95] bert/encoder/transformer/group_0_10/layer_10/inner_group_0/layer_normalization_22/gamma/adam_v/Read/ReadVariableOp:\t\nIn[96] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_23/beta/Read/ReadVariableOp:\t\nIn[97] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_23/beta/adam_m/Read/ReadVariableOp:\t\nIn[98] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_23/beta/adam_v/Read/ReadVariableOp:\t\nIn[99] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_23/gamma/Read/ReadVariableOp:\t\nIn[100] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_23/gamma/adam_m/Read/ReadVariableOp:\t\nIn[101] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_23/gamma/adam_v/Read/ReadVariableOp:\t\nIn[102] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_24/beta/Read/ReadVariableOp:\t\nIn[103] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_24/beta/adam_m/Read/ReadVariableOp:\t\nIn[104] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_24/beta/adam_v/Read/ReadVariableOp:\t\nIn[105] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_24/gamma/Read/ReadVariableOp:\t\nIn[106] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_24/gamma/adam_m/Read/ReadVariableOp:\t\nIn[107] bert/encoder/transformer/group_0_11/layer_11/inner_group_0/layer_normalization_24/gamma/adam_v/Read/ReadVariableOp:\t\nIn[108] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_5/beta/Read/ReadVariableOp:\t\nIn[109] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_5/beta/adam_m/Read/ReadVariableOp:\t\nIn[110] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_5/beta/adam_v/Read/ReadVariableOp:\t\nIn[111] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_5/gamma/Read/ReadVariableOp:\t\nIn[112] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_5/gamma/adam_m/Read/ReadVariableOp:\t\nIn[113] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_5/gamma/adam_v/Read/ReadVariableOp:\t\nIn[114] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_6/beta/Read/ReadVariableOp:\t\nIn[115] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_6/beta/adam_m/Read/ReadVariableOp:\t\nIn[116] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_6/beta/adam_v/Read/ReadVariableOp:\t\nIn[117] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_6/gamma/Read/ReadVariableOp:\t\nIn[118] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_6/gamma/adam_m/Read/ReadVariableOp:\t\nIn[119] bert/encoder/transformer/group_0_2/layer_2/inner_group_0/layer_normalization_6/gamma/adam_v/Read/ReadVariableOp:\t\nIn[120] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_7/beta/Read/ReadVariableOp:\t\nIn[121] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_7/beta/adam_m/Read/ReadVariableOp:\t\nIn[122] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_7/beta/adam_v/Read/ReadVariableOp:\t\nIn[123] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_7/gamma/Read/ReadVariableOp:\t\nIn[124] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_7/gamma/adam_m/Read/ReadVariableOp:\t\nIn[125] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_7/gamma/adam_v/Read/ReadVariableOp:\t\nIn[126] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_8/beta/Read/ReadVariableOp:\t\nIn[127] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_8/beta/adam_m/Read/ReadVariableOp:\t\nIn[128] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_8/beta/adam_v/Read/ReadVariableOp:\t\nIn[129] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_8/gamma/Read/ReadVariableOp:\t\nIn[130] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_8/gamma/adam_m/Read/ReadVariableOp:\t\nIn[131] bert/encoder/transformer/group_0_3/layer_3/inner_group_0/layer_normalization_8/gamma/adam_v/Read/ReadVariableOp:\t\nIn[132] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_10/beta/Read/ReadVariableOp:\t\nIn[133] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_10/beta/adam_m/Read/ReadVariableOp:\t\nIn[134] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_10/beta/adam_v/Read/ReadVariableOp:\t\nIn[135] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_10/gamma/Read/ReadVariableOp:\t\nIn[136] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_10/gamma/adam_m/Read/ReadVariableOp:\t\nIn[137] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_10/gamma/adam_v/Read/ReadVariableOp:\t\nIn[138] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_9/beta/Read/ReadVariableOp:\t\nIn[139] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_9/beta/adam_m/Read/ReadVariableOp:\t\nIn[140] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_9/beta/adam_v/Read/ReadVariableOp:\t\nIn[141] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_9/gamma/Read/ReadVariableOp:\t\nIn[142] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_9/gamma/adam_m/Read/ReadVariableOp:\t\nIn[143] bert/encoder/transformer/group_0_4/layer_4/inner_group_0/layer_normalization_9/gamma/adam_v/Read/ReadVariableOp:\t\nIn[144] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_11/beta/Read/ReadVariableOp:\t\nIn[145] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_11/beta/adam_m/Read/ReadVariableOp:\t\nIn[146] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_11/beta/adam_v/Read/ReadVariableOp:\t\nIn[147] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_11/gamma/Read/ReadVariableOp:\t\nIn[148] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_11/gamma/adam_m/Read/ReadVariableOp:\t\nIn[149] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_11/gamma/adam_v/Read/ReadVariableOp:\t\nIn[150] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_12/beta/Read/ReadVariableOp:\t\nIn[151] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_12/beta/adam_m/Read/ReadVariableOp:\t\nIn[152] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_12/beta/adam_v/Read/ReadVariableOp:\t\nIn[153] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_12/gamma/Read/ReadVariableOp:\t\nIn[154] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_12/gamma/adam_m/Read/ReadVariableOp:\t\nIn[155] bert/encoder/transformer/group_0_5/layer_5/inner_group_0/layer_normalization_12/gamma/adam_v/Read/ReadVariableOp:\t\nIn[156] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_13/beta/Read/ReadVariableOp:\t\nIn[157] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_13/beta/adam_m/Read/ReadVariableOp:\t\nIn[158] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_13/beta/adam_v/Read/ReadVariableOp:\t\nIn[159] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_13/gamma/Read/ReadVariableOp:\t\nIn[160] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_13/gamma/adam_m/Read/ReadVariableOp:\t\nIn[161] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_13/gamma/adam_v/Read/ReadVariableOp:\t\nIn[162] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_14/beta/Read/ReadVariableOp:\t\nIn[163] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_14/beta/adam_m/Read/ReadVariableOp:\t\nIn[164] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_14/beta/adam_v/Read/ReadVariableOp:\t\nIn[165] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_14/gamma/Read/ReadVariableOp:\t\nIn[166] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_14/gamma/adam_m/Read/ReadVariableOp:\t\nIn[167] bert/encoder/transformer/group_0_6/layer_6/inner_group_0/layer_normalization_14/gamma/adam_v/Read/ReadVariableOp:\t\nIn[168] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_15/beta/Read/ReadVariableOp:\t\nIn[169] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_15/beta/adam_m/Read/ReadVariableOp:\t\nIn[170] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_15/beta/adam_v/Read/ReadVariableOp:\t\nIn[171] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_15/gamma/Read/ReadVariableOp:\t\nIn[172] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_15/gamma/adam_m/Read/ReadVariableOp:\t\nIn[173] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_15/gamma/adam_v/Read/ReadVariableOp:\t\nIn[174] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_16/beta/Read/ReadVariableOp:\t\nIn[175] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_16/beta/adam_m/Read/ReadVariableOp:\t\nIn[176] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_16/beta/adam_v/Read/ReadVariableOp:\t\nIn[177] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_16/gamma/Read/ReadVariableOp:\t\nIn[178] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_16/gamma/adam_m/Read/ReadVariableOp:\t\nIn[179] bert/encoder/transformer/group_0_7/layer_7/inner_group_0/layer_normalization_16/gamma/adam_v/Read/ReadVariableOp:\t\nIn[180] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_17/beta/Read/ReadVariableOp:\t\nIn[181] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_17/beta/adam_m/Read/ReadVariableOp:\t\nIn[182] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_17/beta/adam_v/Read/ReadVariableOp:\t\nIn[183] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_17/gamma/Read/ReadVariableOp:\t\nIn[184] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_17/gamma/adam_m/Read/ReadVariableOp:\t\nIn[185] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_17/gamma/adam_v/Read/ReadVariableOp:\t\nIn[186] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_18/beta/Read/ReadVariableOp:\t\nIn[187] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_18/beta/adam_m/Read/ReadVariableOp:\t\nIn[188] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_18/beta/adam_v/Read/ReadVariableOp:\t\nIn[189] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_18/gamma/Read/ReadVariableOp:\t\nIn[190] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_18/gamma/adam_m/Read/ReadVariableOp:\t\nIn[191] bert/encoder/transformer/group_0_8/layer_8/inner_group_0/layer_normalization_18/gamma/adam_v/Read/ReadVariableOp:\t\nIn[192] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_19/beta/Read/ReadVariableOp:\t\nIn[193] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_19/beta/adam_m/Read/ReadVariableOp:\t\nIn[194] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_19/beta/adam_v/Read/ReadVariableOp:\t\nIn[195] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_19/gamma/Read/ReadVariableOp:\t\nIn[196] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_19/gamma/adam_m/Read/ReadVariableOp:\t\nIn[197] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_19/gamma/adam_v/Read/ReadVariableOp:\t\nIn[198] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_20/beta/Read/ReadVariableOp:\t\nIn[199] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_20/beta/adam_m/Read/ReadVariableOp:\t\nIn[200] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_20/beta/adam_v/Read/ReadVariableOp:\t\nIn[201] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_20/gamma/Read/ReadVariableOp:\t\nIn[202] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_20/gamma/adam_m/Read/ReadVariableOp:\t\nIn[203] bert/encoder/transformer/group_0_9/layer_9/inner_group_0/layer_normalization_20/gamma/adam_v/Read/ReadVariableOp:\t\nIn[204] bert/pooler/dense/bias/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer_v1.py:423)\t\nIn[205] bert/pooler/dense/bias/adam_m/Read/ReadVariableOp:\t\nIn[206] bert/pooler/dense/bias/adam_v/Read/ReadVariableOp:\t\nIn[207] bert/pooler/dense/kernel/Read/ReadVariableOp:\t\nIn[208] bert/pooler/dense/kernel/adam_m/Read/ReadVariableOp:\t\nIn[209] bert/pooler/dense/kernel/adam_v/Read/ReadVariableOp:\t\nIn[210] cls/predictions/output_bias/Read/ReadVariableOp (defined at <ipython-input-3-a9c4ee69f617>:21)\t\nIn[211] cls/predictions/output_bias/adam_m/Read/ReadVariableOp:\t\nIn[212] cls/predictions/output_bias/adam_v/Read/ReadVariableOp:\t\nIn[213] cls/predictions/transform/dense/bias/Read/ReadVariableOp:\t\nIn[214] cls/predictions/transform/dense/bias/adam_m/Read/ReadVariableOp:\t\nIn[215] cls/predictions/transform/dense/bias/adam_v/Read/ReadVariableOp:\t\nIn[216] cls/predictions/transform/dense/kernel/Read/ReadVariableOp:\t\nIn[217] cls/predictions/transform/dense/kernel/adam_m/Read/ReadVariableOp:\t\nIn[218] cls/predictions/transform/dense/kernel/adam_v/Read/ReadVariableOp:\t\nIn[219] cls/predictions/transform/layer_normalization_25/beta/Read/ReadVariableOp:\t\nIn[220] cls/predictions/transform/layer_normalization_25/beta/adam_m/Read/ReadVariableOp:\t\nIn[221] cls/predictions/transform/layer_normalization_25/beta/adam_v/Read/ReadVariableOp:\t\nIn[222] cls/predictions/transform/layer_normalization_25/gamma/Read/ReadVariableOp:\t\nIn[223] cls/predictions/transform/layer_normalization_25/gamma/adam_m/Read/ReadVariableOp:\t\nIn[224] cls/predictions/transform/layer_normalization_25/gamma/adam_v/Read/ReadVariableOp:\t\nIn[225] cls/seq_relationship/output_bias/Read/ReadVariableOp (defined at <ipython-input-4-fb70aba96a2b>:12)\t\nIn[226] cls/seq_relationship/output_bias/adam_m/Read/ReadVariableOp:\t\nIn[227] cls/seq_relationship/output_bias/adam_v/Read/ReadVariableOp:\t\nIn[228] cls/seq_relationship/output_weights/Read/ReadVariableOp (defined at <ipython-input-4-fb70aba96a2b>:7)\t\nIn[229] cls/seq_relationship/output_weights/adam_m/Read/ReadVariableOp:\t\nIn[230] cls/seq_relationship/output_weights/adam_v/Read/ReadVariableOp:\t\nIn[231] global_step/Read/ReadVariableOp (defined at C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py:147)\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 381, in dispatch_queue\n>>>     yield self.process_one()\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 250, in wrapper\n>>>     runner = Runner(ctx_run, result, future, yielded)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 741, in __init__\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-9-d55d79ca8a29>\", line 65, in <module>\n>>>     estimator.train(input_fn=train_input_fn, max_steps=PARAMS_num_train_steps)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 3092, in train\n>>>     return super(TPUEstimator, self).train(\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 360, in train\n>>>     loss = self._train_model(input_fn, hooks, saving_listeners)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1186, in _train_model\n>>>     return self._train_model_default(input_fn, hooks, saving_listeners)\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1217, in _train_model_default\n>>>     return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n>>> \n>>>   File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1512, in _train_with_estimator_spec\n>>>     with training.MonitoredTrainingSession(\n>>> \n\nOriginal stack trace for 'save/SaveV2':\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 381, in dispatch_queue\n    yield self.process_one()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 250, in wrapper\n    runner = Runner(ctx_run, result, future, yielded)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 741, in __init__\n    self.ctx_run(self.run)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n    self.do_execute(\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n    result = self._run_cell(\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-d55d79ca8a29>\", line 65, in <module>\n    estimator.train(input_fn=train_input_fn, max_steps=PARAMS_num_train_steps)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 3092, in train\n    return super(TPUEstimator, self).train(\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 360, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1186, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1217, in _train_model_default\n    return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1512, in _train_with_estimator_spec\n    with training.MonitoredTrainingSession(\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 613, in MonitoredTrainingSession\n    return MonitoredSession(\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1058, in __init__\n    super(MonitoredSession, self).__init__(\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 761, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1267, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1272, in _create_session\n    return self._sess_creator.create_session()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 914, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 672, in create_session\n    self._scaffold.finalize()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 244, in finalize\n    self._saver.build()\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 935, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 963, in _build\n    self.saver_def = self._builder._build_internal(  # pylint: disable=protected-access\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 525, in _build_internal\n    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 317, in _AddShardedSaveOps\n    return self._AddShardedSaveOpsForV2(filename_tensor, per_device)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 291, in _AddShardedSaveOpsForV2\n    sharded_saves.append(self._AddSaveOps(sharded_filename, saveables))\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 223, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 138, in save_op\n    return io_ops.save_v2(filename_tensor, tensor_names, tensor_slices,\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1712, in save_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 744, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3697, in _create_op_internal\n    ret = Operation(\n  File \"C:\\Users\\XinXining\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2101, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "if not PARAMS_do_train and not PARAMS_do_eval:\n",
    "    raise ValueError(\"At least one of `do_train` or `do_eval` must be True.\")\n",
    "\n",
    "albert_config = modeling.AlbertConfig.from_json_file(PARAMS_albert_config_file)\n",
    "\n",
    "tf.gfile.MakeDirs(PARAMS_output_dir)\n",
    "\n",
    "input_files = []\n",
    "for input_pattern in PARAMS_input_file.split(\",\"):\n",
    "    input_files.extend(tf.gfile.Glob(input_pattern))\n",
    "\n",
    "tf.logging.info(\"*** Input Files ***\")\n",
    "for input_file in input_files:\n",
    "    tf.logging.info(\"  %s\" % input_file)\n",
    "\n",
    "tpu_cluster_resolver = None\n",
    "if PARAMS_use_tpu and PARAMS_tpu_name:\n",
    "    tpu_cluster_resolver = tensorflow.distribute.cluster_resolver.TPUClusterResolver(\n",
    "    PARAMS_tpu_name, zone=PARAMS_tpu_zone, project=PARAMS_gcp_project)\n",
    "\n",
    "# is_per_host = tensorflow.estimator.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "is_per_host = tf.estimator.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "run_config = tf.estimator.tpu.RunConfig(\n",
    "    cluster=tpu_cluster_resolver,\n",
    "    master=PARAMS_master,\n",
    "    model_dir=PARAMS_output_dir,\n",
    "    save_checkpoints_steps=PARAMS_save_checkpoints_steps,\n",
    "    keep_checkpoint_max=PARAMS_keep_checkpoint_max,\n",
    "    tpu_config=tf.estimator.tpu.TPUConfig(\n",
    "        iterations_per_loop=PARAMS_iterations_per_loop,\n",
    "        num_shards=PARAMS_num_tpu_cores,\n",
    "        per_host_input_for_training=is_per_host))\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "    albert_config=albert_config,\n",
    "    init_checkpoint=PARAMS_init_checkpoint,\n",
    "    learning_rate=PARAMS_learning_rate,\n",
    "    num_train_steps=PARAMS_num_train_steps,\n",
    "    num_warmup_steps=PARAMS_num_warmup_steps,\n",
    "    use_tpu=PARAMS_use_tpu,\n",
    "    use_one_hot_embeddings=PARAMS_use_tpu,\n",
    "    optimizer=PARAMS_optimizer,\n",
    "    poly_power=PARAMS_poly_power,\n",
    "    start_warmup_step=PARAMS_start_warmup_step)\n",
    "\n",
    "# If TPU is not available, this will fall back to normal Estimator on CPU\n",
    "# or GPU.\n",
    "estimator = tf.estimator.tpu.TPUEstimator(\n",
    "    use_tpu=PARAMS_use_tpu,\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    train_batch_size=PARAMS_train_batch_size,\n",
    "    eval_batch_size=PARAMS_eval_batch_size)\n",
    "\n",
    "if PARAMS_do_train:\n",
    "    tf.logging.info(\"***** Running training *****\")\n",
    "    # tf.logging.info(\"  Batch size = %d\", PARAMS_train_batch_size)\n",
    "    train_input_fn = input_fn_builder(\n",
    "        input_files=input_files,\n",
    "        max_seq_length=PARAMS_max_seq_length,\n",
    "        max_predictions_per_seq=PARAMS_max_predictions_per_seq,\n",
    "        is_training=True)\n",
    "    estimator.train(input_fn=train_input_fn, max_steps=PARAMS_num_train_steps)\n",
    "\n",
    "if PARAMS_do_eval:\n",
    "    tf.logging.info(\"***** Running evaluation *****\")\n",
    "    # tf.logging.info(\"  Batch size = %d\", PARAMS_eval_batch_size)\n",
    "    global_step = -1\n",
    "    output_eval_file = os.path.join(PARAMS_output_dir, \"eval_results.txt\")\n",
    "    writer = tf.gfile.GFile(output_eval_file, \"w\")\n",
    "    eval_input_fn = input_fn_builder(\n",
    "        input_files=input_files,\n",
    "        max_seq_length=PARAMS_max_seq_length,\n",
    "        max_predictions_per_seq=PARAMS_max_predictions_per_seq,\n",
    "        is_training=False)\n",
    "    best_perf = 0\n",
    "    key_name = \"masked_lm_accuracy\"\n",
    "    while global_step < PARAMS_num_train_steps:\n",
    "        if estimator.latest_checkpoint() is None:\n",
    "            tf.logging.info(\"No checkpoint found yet. Sleeping.\")\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            result = estimator.evaluate(\n",
    "                input_fn=eval_input_fn, steps=PARAMS_max_eval_steps)\n",
    "            global_step = result[\"global_step\"]\n",
    "            tf.logging.info(\"***** Eval results *****\")\n",
    "            checkpoint_path = estimator.latest_checkpoint()\n",
    "            for key in sorted(result.keys()):\n",
    "                # tf.logging.info(\"  %s = %s\", key, str(result[key]))\n",
    "                writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "                if result[key_name] > best_perf:\n",
    "                    best_perf = result[key_name]\n",
    "                    for ext in [\"meta\", \"data-00000-of-00001\", \"index\"]:\n",
    "                        src_ckpt = checkpoint_path + \".{}\".format(ext)\n",
    "                        tgt_ckpt = checkpoint_path.rsplit(\n",
    "                          \"-\", 1)[0] + \"-best.{}\".format(ext)\n",
    "                        # tf.logging.info(\"saving {} to {}\".format(src_ckpt, tgt_ckpt))\n",
    "                        tf.gfile.Copy(src_ckpt, tgt_ckpt, overwrite=True)\n",
    "                        writer.write(\"saved {} to {}\\n\".format(src_ckpt, tgt_ckpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee5d86b-35cb-4634-a353-11344d6817ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
